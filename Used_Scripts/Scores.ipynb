{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M² Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errant\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sentences = []\n",
    "incorr_sentences = []\n",
    "\n",
    "with open(\"../predictions/_test_set/incorr_sentences.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        incorr_sentences.append(line.replace(\"\\n\", \"\").strip())\n",
    "\n",
    "with open(\"../predictions/_test_set/corr_sentences.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        corr_sentences.append(line.replace(\"\\n\", \"\").strip())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "annotator = errant.load(\"en\", nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sentences = \"\"\n",
    "for i in range(len(corr_sentences)):\n",
    "    orig = annotator.parse(incorr_sentences[i])\n",
    "    cor = annotator.parse(corr_sentences[i])\n",
    "    edits = annotator.annotate(orig, cor)\n",
    "    \n",
    "    source_gold = \"S {}\\n\".format(incorr_sentences[i])\n",
    "    for e in edits:\n",
    "        source_gold += e.to_m2() + \"\\n\"\n",
    "    source_gold += \"\\n\"\n",
    "    annotated_sentences += source_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../predictions/_test_set/source_gold.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(annotated_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung des M²-Score erfolgt über die Kommandozeile. Ergebnisse sind in Predictions.xsls einzusehen.\n",
    "- CMD-Command: python [path to m2scorer.py -v [path to predicted sequences] [path to source gold file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung des GLEU-Score erfolgt über die Kommandozeile. Ergebnisse sind in Predictions.xsls einzusehen.\n",
    "- CMD-Command: python gleu.py --ref [path to reference file --src [path to source file --hyp [path to predicted sequences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_retrained_20_epochs': 86.04120292988149, 'fairseq-gec_retrained_20_epochs': 80.4063024763165, 'pie_original': 79.33410274512904, 'pie_retrained_4_epochs': 84.63069555757671, 'roberta_retrained_20_epochs': 86.717062463897, 'xlnet_retrained_20_epochs': 87.57611809219638, 'ensemble_bert_roberta_xlnet': 88.87053843050312, 'ensemble_roberta_xlnet': 88.64474596743764}\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "scores = dict()\n",
    "\n",
    "path_names = [] #folders of model predicitons\n",
    "path = \"\" #path to predictions folder\n",
    "filename = \"preds.txt\"\n",
    "\n",
    "for name in path_names:\n",
    "    text = None\n",
    "    predictions = []\n",
    "    corr_sentences = []\n",
    "    with open(path+name+\"/\"+filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            predictions.append(line.replace(\"\\n\",\"\"))\n",
    "    with open(\"\") as f: #path to correct sentences\n",
    "        for line in f:\n",
    "            corr_sentences.append(line.replace(\"\\n\",\"\"))\n",
    "    scores[name] = sacrebleu.corpus_bleu(predictions, [corr_sentences]).score\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_retrained_20_epochs': {'rouge-1': {'f': 0.933078112890877, 'p': 0.9359411070734943, 'r': 0.9316306138779541}, 'rouge-2': {'f': 0.8520216050475314, 'p': 0.8546095132956729, 'r': 0.8507791924990539}, 'rouge-l': {'f': 0.9361705527555386, 'p': 0.940370858232851, 'r': 0.9334329582115372}}, 'fairseq-gec_retrained_20_epochs': {'rouge-1': {'f': 0.9091608418263931, 'p': 0.9240253926386699, 'r': 0.8968084988353872}, 'rouge-2': {'f': 0.8018124679568831, 'p': 0.8150830867936414, 'r': 0.7908176584177097}, 'rouge-l': {'f': 0.912661248144578, 'p': 0.9254012113870488, 'r': 0.9024188836269091}}, 'pie_original': {'rouge-1': {'f': 0.8546922318129169, 'p': 0.860433035362708, 'r': 0.8520537734779213}, 'rouge-2': {'f': 0.7293315479097878, 'p': 0.7341823946569631, 'r': 0.7272826513721374}, 'rouge-l': {'f': 0.8584566146779714, 'p': 0.863116476637231, 'r': 0.8566380163367263}}, 'pie_retrained_4_epochs': {'rouge-1': {'f': 0.8796123450020198, 'p': 0.8760589560326062, 'r': 0.885558680283543}, 'rouge-2': {'f': 0.776159175958265, 'p': 0.7730861351358644, 'r': 0.7814460862205093}, 'rouge-l': {'f': 0.8823185870973224, 'p': 0.8811995226574817, 'r': 0.8854126589665864}}, 'roberta_retrained_20_epochs': {'rouge-1': {'f': 0.9400591589933118, 'p': 0.9471209168016477, 'r': 0.9344080364518199}, 'rouge-2': {'f': 0.8682211929242263, 'p': 0.8747807354450167, 'r': 0.8630550337646784}, 'rouge-l': {'f': 0.9435693583395817, 'p': 0.9501351791131396, 'r': 0.9384033739013985}}, 'xlnet_retrained_20_epochs': {'rouge-1': {'f': 0.9429174656266899, 'p': 0.9455889013296016, 'r': 0.9416723957309465}, 'rouge-2': {'f': 0.8723400284406384, 'p': 0.8749425653387737, 'r': 0.8711101014297481}, 'rouge-l': {'f': 0.9462492205022935, 'p': 0.9503972137188387, 'r': 0.9434857192894635}}, 'ensemble_bert_roberta_xlnet': {'rouge-1': {'f': 0.9489194984665428, 'p': 0.9552940418499725, 'r': 0.9437204487813722}, 'rouge-2': {'f': 0.8861739933853433, 'p': 0.8920812348399721, 'r': 0.8814016882923659}, 'rouge-l': {'f': 0.9517795876522427, 'p': 0.9580153913900857, 'r': 0.9466215737832143}}, 'ensemble_roberta_xlnet': {'rouge-1': {'f': 0.9478127419113799, 'p': 0.9552303289928996, 'r': 0.941636241873372}, 'rouge-2': {'f': 0.8850663735866098, 'p': 0.8919679194890857, 'r': 0.8793824611769968}, 'rouge-l': {'f': 0.9516177793195293, 'p': 0.9590159578961814, 'r': 0.9454078057134212}}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import FilesRouge\n",
    "\n",
    "scores = dict()\n",
    "\n",
    "refPath = \"\" #path to reference file\n",
    "path_names = [] #folders of model predictions\n",
    "path = \"\" #path to predictions folder\n",
    "filename = \"preds_utf.txt\"\n",
    "\n",
    "for name in path_names:\n",
    "    files_rouge = FilesRouge()\n",
    "    scores_ = files_rouge.get_scores(path+name+\"/\"+filename, refPath, avg=True)\n",
    "    scores[name] = scores_\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umwandlung pred.txt in UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_names = [\"bert_retrained_20_epochs\",\"fairseq-gec_retrained_20_epochs\",\"pie_original\",\"pie_retrained_4_epochs\",\"roberta_retrained_20_epochs\",\"xlnet_retrained_20_epochs\",\"ensemble_bert_roberta_xlnet\",\"ensemble_roberta_xlnet\"]\n",
    "path = \"G:/Github_Repos/Bachelorarbeit/predictions/\"\n",
    "filename = \"preds.txt\"\n",
    "new_filename = \"preds_utf.txt\"\n",
    "\n",
    "for name in path_names:\n",
    "    text = None\n",
    "    with open(path+name+\"/\" + filename, \"r\") as f:\n",
    "        text = f.read()\n",
    "    with open(path+name+\"/\"+new_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umwandlung corr_sentences.txt in UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"G:/Github_Repos/Bachelorarbeit/predictions/_test_set/corr_sentences.txt\"\n",
    "path2 = \"G:/Github_Repos/Bachelorarbeit/predictions/_test_set/corr_sentences_utf.txt\"\n",
    "with open(path, \"r\") as f:\n",
    "    text = f.read()\n",
    "with open(path2, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
